import streamlit as st
import pandas as pd
import os
import glob
import requests
from datetime import datetime, date

# 1. í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="ì—°ë„ë³„ ìŒë£Œ ë¶„ì„ ëŒ€ì‹œë³´ë“œ", layout="wide")

# --- [ë°ì´í„° ìˆ˜ì§‘] ---
def run_collector(api_key):
    url = f"http://openapi.foodsafetykorea.go.kr/api/{api_key}/I1250/json/1/500"
    try:
        response = requests.get(url, timeout=15)
        data = response.json()
        if 'I1250' not in data: return False
        rows = data['I1250']['row']
        api_df = pd.DataFrame(rows)
        api_df = api_df.loc[:, ~api_df.columns.duplicated()].copy()
        mapping = {
            'BSSH_NM': 'brand_owner', 'PRMS_DT': 'ì¶œì‹œë…„ë„', 
            'PRDLST_NM': 'brand_name', 'PRDLST_DCLS_NM': 'ìŒë£Œìœ í˜•', 
            'RAWMATERIAL_NM': 'ì›ì¬ë£Œí‘œì‹œ', 'LAST_UPDT_DT': 'ìµœì¢…ìˆ˜ì •ì¼ì'
        }
        api_df = api_df.rename(columns=mapping)
        api_df['ìµœì¢…ìˆ˜ì •ì¼ì'] = pd.to_datetime(api_df['ìµœì¢…ìˆ˜ì •ì¼ì'], errors='coerce').dt.strftime('%Y-%m-%d')
        api_df['ì¶œì‹œë…„ë„'] = api_df['ì¶œì‹œë…„ë„'].astype(str).str[:4]
        if not os.path.exists('data'): os.makedirs('data')
        api_df.to_csv("data/beverage_api_data.csv", index=False, encoding='utf-8-sig')
        return True
    except: return False

# --- [ë°ì´í„° ë¡œë“œ] ---
@st.cache_data
def load_all_data():
    files = glob.glob(os.path.join("data", "*.csv")) + glob.glob("*.csv")
    if not files: return None
    std_cols = ['ìŒë£Œìœ í˜•', 'brand_owner', 'brand_name', 'ì›ì¬ë£Œí‘œì‹œ', 'ì¶œì‹œë…„ë„', 'ìµœì¢…ìˆ˜ì •ì¼ì']
    df_list = []
    for f in set(files):
        try:
            try: tmp = pd.read_csv(f, encoding='utf-8-sig')
            except: tmp = pd.read_csv(f, encoding='cp949')
            tmp = tmp.loc[:, ~tmp.columns.duplicated()].copy()
            tmp = tmp.rename(columns={'í’ˆëª©ìœ í˜•ëª…': 'ìŒë£Œìœ í˜•', 'ì—…ì†Œëª…': 'brand_owner', 'ì œí’ˆëª…': 'brand_name'})
            for col in std_cols:
                if col not in tmp.columns: tmp[col] = "ë¯¸í‘œê¸°"
            df_list.append(tmp[std_cols].reset_index(drop=True))
        except: continue
    full_df = pd.concat(df_list, axis=0, ignore_index=True)
    full_df['ì¶œì‹œë…„ë„'] = pd.to_numeric(full_df['ì¶œì‹œë…„ë„'], errors='coerce').fillna(2024).astype(int)
    full_df['ìˆ˜ì •ì¼_dt'] = pd.to_datetime(full_df['ìµœì¢…ìˆ˜ì •ì¼ì'], errors='coerce').dt.date
    
    # ê°ë¯¸ë£Œ ì¶”ì¶œ ë¡œì§
    sweets = ['ìˆ˜í¬ë„ë¡œìŠ¤', 'ì•„ìŠ¤íŒŒíƒ', 'ì•„ì„¸ì„¤íŒœì¹¼ë¥¨', 'ìŠ¤í…Œë¹„ì•„', 'ì—ë¦¬ìŠ¤ë¦¬í†¨', 'ì•Œë£°ë¡œìŠ¤', 'ì„¤íƒ•']
    full_df['ì£¼ìš”ë‹¹_ê°ë¯¸ë£Œ'] = full_df['ì›ì¬ë£Œí‘œì‹œ'].apply(lambda x: ", ".join([s for s in sweets if s in str(x)]) or "ë¯¸í‘œê¸°")
    return full_df

df = load_all_data()

# --- [ì‚¬ì´ë“œë°” í•„í„°: ì—°ë„ ê²€ìƒ‰ í•µì‹¬] ---
with st.sidebar:
    st.title("ğŸ” ì œí’ˆ ì—°ë„ ê²€ìƒ‰")
    if st.button("ğŸ”„ ìµœì‹  ë°ì´í„° ìˆ˜ì§‘"):
        if run_collector("9171f7ffd72f4ffcb62f"):
            st.cache_data.clear()
            st.rerun()

    if df is not None:
        st.divider()
        # [ìš”ì²­ì‚¬í•­ ë°˜ì˜] ì—°ë„ ê²€ìƒ‰ ìŠ¬ë¼ì´ë”
        min_y, max_y = int(df['ì¶œì‹œë…„ë„'].min()), int(df['ì¶œì‹œë…„ë„'].max())
        search_year = st.slider("ğŸ“… ì¶œì‹œë…„ë„ ë²”ìœ„ ê²€ìƒ‰", min_y, max_y, (2020, 2024))
        
        # [ì‹ì•½ì²˜ ìˆ˜ì •ì¼ì í•„í„°]
        valid_dates = df['ìˆ˜ì •ì¼_dt'].dropna().unique()
        if len(valid_dates) > 0:
            date_range = st.slider("ğŸ—“ï¸ ì‹ì•½ì²˜ ìˆ˜ì •ì¼ì ë²”ìœ„", min(valid_dates), max(valid_dates), (min(valid_dates), max(valid_dates)))
        else:
            date_range = (date.today(), date.today())

# --- [ë©”ì¸ í™”ë©´: ê²€ìƒ‰ëœ ì œí’ˆë§Œ ì¶œë ¥] ---
if df is not None:
    # 1. ì—°ë„ ê¸°ë°˜ í•„í„°ë§ (ë©”ì¸ ë°ì´í„°)
    filtered_df = df[(df['ì¶œì‹œë…„ë„'] >= search_year[0]) & (df['ì¶œì‹œë…„ë„'] <= search_year[1])]
    
    # 2. ì‹ì•½ì²˜ ìˆ˜ì •ì¼ì ê¸°ë°˜ í•„í„°ë§
    api_filtered_df = df[(df['ìˆ˜ì •ì¼_dt'] >= date_range[0]) & (df['ìˆ˜ì •ì¼_dt'] <= date_range[1])]

    tab1, tab2 = st.tabs(["ğŸ“Š ì—°ë„ë³„ ì¶œì‹œì œí’ˆ ë¶„ì„", "ğŸ” ì‹ì•½ì²˜ ë‚ ì§œë³„ ìƒì„¸ì¡°íšŒ"])

    with tab1:
        st.header(f"ğŸ¥¤ {search_year[0]}ë…„ ~ {search_year[1]}ë…„ ì¶œì‹œ ì œí’ˆ")
        
        if not filtered_df.empty:
            m1, m2 = st.columns(2)
            with m1:
                st.subheader("ğŸ¢ ë¸Œëœë“œë³„ ì¶œì‹œ ìˆœìœ„")
                st.bar_chart(filtered_df['brand_owner'].value_counts().head(10))
            with m2:
                st.subheader("ğŸ‹ ì œí’ˆë³„ í”Œë ˆì´ë²„ ë¶„í¬")
                flavor_list = ['APPLE', 'PEACH', 'LEMON', 'GRAPE', 'STRAWBERRY']
                filtered_df['Flavor'] = filtered_df['brand_name'].apply(lambda x: next((f for f in flavor_list if f in str(x).upper()), "ê¸°íƒ€"))
                st.bar_chart(filtered_df['Flavor'].value_counts())
            
            st.subheader(f"ğŸ“‹ {search_year[0]}~{search_year[1]} ì¶œì‹œ ì œí’ˆ ë¦¬ìŠ¤íŠ¸")
            st.dataframe(
                filtered_df.sort_values('ì¶œì‹œë…„ë„', ascending=False)[['ì¶œì‹œë…„ë„', 'brand_owner', 'brand_name', 'ìŒë£Œìœ í˜•', 'ì£¼ìš”ë‹¹_ê°ë¯¸ë£Œ']], 
                use_container_width=True, hide_index=True
            )
        else:
            st.warning("ì„ íƒí•œ ì—°ë„ì— ì¶œì‹œëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")

    with tab2:
        st.header("ğŸ“… ì‹ì•½ì²˜ ì—…ë°ì´íŠ¸ í˜„í™©")
        st.write(f"ì¡°íšŒ ë²”ìœ„: {date_range[0]} ~ {date_range[1]}")
        st.dataframe(
            api_filtered_df.sort_values('ìµœì¢…ìˆ˜ì •ì¼ì', ascending=False)[['ìµœì¢…ìˆ˜ì •ì¼ì', 'brand_owner', 'brand_name', 'ìŒë£Œìœ í˜•']], 
            use_container_width=True, hide_index=True
        )
else:
    st.info("ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ì—…ë°ì´íŠ¸ ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
